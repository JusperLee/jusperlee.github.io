{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "fHkHcMsAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Kai Li (李凯)", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=fHkHcMsAAAAJ&citpid=3", "affiliation": "Tsinghua University", "organization": 15442380624744264287, "interests": ["Speech separation", "Audio-visual deep learning"], "email_domain": "@mails.tsinghua.edu.cn", "homepage": "https://cslikai.cn/", "citedby": 885, "publications": {"fHkHcMsAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Survey of single image super‐resolution reconstruction", "pub_year": "2020"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:u5HHmVD_uO8C", "num_citations": 117, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2196172608226737263", "cites_id": ["2196172608226737263"]}, "fHkHcMsAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An efficient encoder-decoder architecture with top-down attention for speech separation", "pub_year": "2022"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:7PzlFSSx8tAC", "num_citations": 85, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18312439897558314547", "cites_id": ["18312439897558314547"]}, "fHkHcMsAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Spmamba: State-space model is all you need in speech separation", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:L8Ckcad2t8MC", "num_citations": 82, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6109468475310385161", "cites_id": ["6109468475310385161"]}, "fHkHcMsAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Speech separation using an asynchronous fully recurrent convolutional neural network", "pub_year": "2021"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:zYLM7Y9cAGgC", "num_citations": 71, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11722770519480068778", "cites_id": ["11722770519480068778"]}, "fHkHcMsAAAAJ:-f6ydRqryjwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal From Optical Satellite Images", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:-f6ydRqryjwC", "num_citations": 68, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8125489781068627197,1538495243428599431", "cites_id": ["8125489781068627197", "1538495243428599431"]}, "fHkHcMsAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The Sound Demixing Challenge 2023-Music Demixing Track", "pub_year": "2023"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:TQgYirikUcIC", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13221551585854774831", "cites_id": ["13221551585854774831"]}, "fHkHcMsAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Safeear: Content privacy-preserving audio deepfake detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:e5wmG9Sq2KIC", "num_citations": 44, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15878916099036085548", "cites_id": ["15878916099036085548"]}, "fHkHcMsAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LEFormer: A hybrid CNN-transformer architecture for accurate lake extraction from remote sensing imagery", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:qUcmZB5y_30C", "num_citations": 37, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=742736741020453987", "cites_id": ["742736741020453987"]}, "fHkHcMsAAAAJ:M05iB0D1s5AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio, Music, and Their Mix", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:M05iB0D1s5AC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18247094930564881082", "cites_id": ["18247094930564881082"]}, "fHkHcMsAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An audio-visual speech separation model inspired by cortico-thalamo-cortical circuits", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:ZeXyd9-uunAC", "num_citations": 32, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10787290484677439361", "cites_id": ["10787290484677439361"]}, "fHkHcMsAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PMAA: A progressive multi-scale attention autoencoder model for high-performance cloud removal from multi-temporal satellite imagery", "pub_year": "2023"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:dhFuZR0502QC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11530400887222391256", "cites_id": ["11530400887222391256"]}, "fHkHcMsAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "IIANet: An Intra- and Inter-Modality Attention Network for Audio-Visual Speech Separation", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:4DMP91E08xMC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2500030617904702922,14409728404456320499", "cites_id": ["2500030617904702922", "14409728404456320499"]}, "fHkHcMsAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Neural State-Space Model Approach to Efficient Speech Separation", "pub_year": "2023"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:UebtZRa9Y70C", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14705332555929546253", "cites_id": ["14705332555929546253"]}, "fHkHcMsAAAAJ:fPk4N6BV_jEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sepprune: Structured pruning for efficient deep speech separation", "pub_year": "2026"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:fPk4N6BV_jEC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7437580814953607197", "cites_id": ["7437580814953607197"]}, "fHkHcMsAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-Visual Speech Separation in Noisy Environments with a Lightweight Iterative Model", "pub_year": "2023"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:hqOjcs7Dif8C", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7279269673628583910", "cites_id": ["7279269673628583910"]}, "fHkHcMsAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RTFS-Net: Recurrent time-frequency modelling for efficient audio-visual speech separation", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:_kc_bZDykSQC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11019712777421299341", "cites_id": ["11019712777421299341"]}, "fHkHcMsAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "On the Design and Training Strategies for RNN-based Online Neural Speech Separation Systems", "pub_year": "2023"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:YsMSGLbcyi4C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11364353797073891767", "cites_id": ["11364353797073891767"]}, "fHkHcMsAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "On the use of deep mask estimation module for neural source separation systems", "pub_year": "2022"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:_FxGoFyzp5QC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11332021629388512413", "cites_id": ["11332021629388512413"]}, "fHkHcMsAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The Sound Demixing Challenge 2023-Cinematic Demixing Track.", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:_Qo2XoVZTnwC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5046914067389992768", "cites_id": ["5046914067389992768"]}, "fHkHcMsAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Inferring mechanisms of auditory attentional modulation with deep neural networks", "pub_year": "2022"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:ufrVoPGSRksC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14417488086302819462", "cites_id": ["14417488086302819462"]}, "fHkHcMsAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Single image super-resolution reconstruction of enhanced loss function with multi-gpu training", "pub_year": "2019"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:9yKSN-GCB0IC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16694484233822916697", "cites_id": ["16694484233822916697"]}, "fHkHcMsAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:4JMBOYKVnBMC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8591978435228503176", "cites_id": ["8591978435228503176"]}, "fHkHcMsAAAAJ:R3hNpaxXUhUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards robust pansharpening: A large-scale high-resolution multi-scene dataset and novel approach", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:R3hNpaxXUhUC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13430687025690036694,12250387942264540450", "cites_id": ["13430687025690036694", "12250387942264540450"]}, "fHkHcMsAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Apollo: Band-sequence Modeling for High-Quality Audio Restoration", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:RHpTSmoSYBkC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16527543249519500040", "cites_id": ["16527543249519500040"]}, "fHkHcMsAAAAJ:j3f4tGmQtD8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:j3f4tGmQtD8C", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=979305994459678117", "cites_id": ["979305994459678117"]}, "fHkHcMsAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subnetwork-to-go: Elastic neural network with dynamic training and customizable inference", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:IWHjjKOFINEC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7807137781777773421", "cites_id": ["7807137781777773421"]}, "fHkHcMsAAAAJ:u_35RYKgDlwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Advances in speech separation: Techniques, challenges, and future trends", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:u_35RYKgDlwC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8099711325403537099", "cites_id": ["8099711325403537099"]}, "fHkHcMsAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audiotrust: Benchmarking the multifaceted trustworthiness of audio large language models", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:lSLTfruPkqcC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17970882200880460314", "cites_id": ["17970882200880460314"]}, "fHkHcMsAAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TDFNet: An Efficient Audio-Visual Speech Separation Model with Top-down Fusion", "pub_year": "2023"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:hC7cP41nSMkC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4808340027242931124", "cites_id": ["4808340027242931124"]}, "fHkHcMsAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dynamic Dictionary Learning for Remote Sensing Image Segmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:RGFaLdJalmkC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17136637621992698699", "cites_id": ["17136637621992698699"]}, "fHkHcMsAAAAJ:r0BpntZqJG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adapting vision foundation models for robust cloud segmentation in remote sensing images", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:r0BpntZqJG4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2667591439055175561", "cites_id": ["2667591439055175561"]}, "fHkHcMsAAAAJ:70eg2SAEIzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SoloSpeech: Enhancing Intelligibility and Quality in Target Speech Extraction through a Cascaded Generative Pipeline", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:70eg2SAEIzsC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16444571267676708054", "cites_id": ["16444571267676708054"]}, "fHkHcMsAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:iH-uZ7U-co4C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9638367094067496379", "cites_id": ["9638367094067496379"]}, "fHkHcMsAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "High-Fidelity Lake Extraction via Two-Stage Prompt Enhancement: Establishing a Novel Baseline and Benchmark", "pub_year": "2024"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:YOwf2qJgpHMC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12600152161688211984", "cites_id": ["12600152161688211984"]}, "fHkHcMsAAAAJ:J_g5lzvAfSwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Time-Frequency-Based Attention Cache Memory Model for Real-Time Speech Separation", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:J_g5lzvAfSwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2385454613716557636", "cites_id": ["2385454613716557636"]}, "fHkHcMsAAAAJ:35N4QoGY0k4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Single Image Super-Resolution Through Image Pixel Information Clustering and Generative Adversarial Network", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:35N4QoGY0k4C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2994140003071071160", "cites_id": ["2994140003071071160"]}, "fHkHcMsAAAAJ:zA6iFVUQeVQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation", "pub_year": "2026"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:zA6iFVUQeVQC", "num_citations": 0}, "fHkHcMsAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "BridgeVoC: Revitalizing Neural Vocoder from a Restoration Perspective", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:rO6llkc54NcC", "num_citations": 0}, "fHkHcMsAAAAJ:vV6vV6tmYwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Fast and Lightweight Model for Causal Audio-Visual Speech Separation", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:vV6vV6tmYwMC", "num_citations": 0}, "fHkHcMsAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Critical Information Only: A Content Privacy-Preserving Framework for Detecting Audio Deepfakes", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:ZHo1McVdvXMC", "num_citations": 0}, "fHkHcMsAAAAJ:HoB7MX3m0LUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:HoB7MX3m0LUC", "num_citations": 0}, "fHkHcMsAAAAJ:pqnbT2bcN3wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GDSR: Global-Detail Integration through Dual-Branch Network with Wavelet Losses for Remote Sensing Image Super-Resolution", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:pqnbT2bcN3wC", "num_citations": 0}, "fHkHcMsAAAAJ:SeFeTyx0c_EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unsupervised Single-Channel Speech Separation with a Diffusion Prior under Speaker-Embedding Guidance", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:SeFeTyx0c_EC", "num_citations": 0}, "fHkHcMsAAAAJ:g5m5HwL7SMYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:g5m5HwL7SMYC", "num_citations": 0}, "fHkHcMsAAAAJ:2P1L_qKh6hAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Spectrogram Realism in Singing Voice Synthesis via Explicit Bandwidth Extension Prior to Vocoder", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:2P1L_qKh6hAC", "num_citations": 0}, "fHkHcMsAAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Knowledge Transfer and Domain Adaptation for Fine-Grained Remote Sensing Image Segmentation", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:bEWYMUwI8FkC", "num_citations": 0}, "fHkHcMsAAAAJ:3s1wT3WcHBgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "BAV-MossFormer2: Enhanced MossFormer2 for Binaural Audio-Visual Speech Enhancement", "pub_year": "2025"}, "filled": false, "author_pub_id": "fHkHcMsAAAAJ:3s1wT3WcHBgC", "num_citations": 0}}, "citedby5y": 885, "hindex": 16, "hindex5y": 16, "i10index": 23, "i10index5y": 23, "cites_per_year": {"2021": 20, "2022": 25, "2023": 84, "2024": 246, "2025": 502}, "updated": "2025-12-11 08:33:36.601740"}