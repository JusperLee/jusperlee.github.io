
# ðŸ“ Publications

> ( <sup>*</sup> equal contribution, <sup>#</sup> corresponding author)

## ðŸŽ™ Speech Separation

<div class='paper-box'><div class='paper-box-image'><div><div class="badge" style="background-color: green">Neural Computation 2022</div><img src='images/nerualcom.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Inferring mechanisms of auditory attentional modulation with deep neural networks](./files/neural.pdf)

Ting-Yu Kuo, Yuanda Liao, **Kai Li**, Bo Hong, Xiaolin Hu.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge" style="background-color: green">Submitted Nature Machine Intelligence</div><img src='images/submitted.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An Auditory-Visual Speech Separation Model Inspired by Cortico-thalamo-cortical Circuits]()

**Kai Li**, Fenghua Xie, Hang Chen, Kexin Yuan, Xiaolin Hu.

<a href="https://github.com/liaoyd16/cocktail_lk"><img src="https://img.shields.io/github/starsliaoyd16/cocktail_lk?style=social&amp;label=Code+Stars" alt=""></a>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">InterSpeech 2022</div><img src='images/overss.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[On the Use of Deep Mask Estimation Module for Neural Source Separation Systems](http://arxiv.org/pdf/2206.07347v1)

**Kai Li**, Xiaolin Hu, Yi Luo.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2022</div><img src='images/causal.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[On the Design and Training Strategies for RNN-based Online Neural Speech Separation Systems](http://arxiv.org/pdf/2206.07347v1)

**Kai Li**, Yi Luo.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2022</div><img src='images/afrcnn.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Speech Separation Using an Asynchronous Fully Recurrent Convolutional Neural Network](https://papers.nips.cc/paper/2021/file/be1bc7997695495f756312886f566110-Paper.pdf)

Xiaolin Hu<sup>*, #</sup>, **Kai Li$^*$**, Weiyi Zhang, Yi Luo, Jean-Marie Lemercier, Timo Gerkmann.

[**Audio Demo Page**](./project/AFRCNN) \| [**Speech Enhancement Demo**](./project/AFRCNN-Enh) \| <a href="https://github.com/JusperLee/AFRCNN-For-Speech-Separation"><img src="https://img.shields.io/github/stars/JusperLee/AFRCNN-For-Speech-Separation?style=social&amp;label=Code+Stars" alt=""></a> \| **Citations: 6**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Bachelor Degree Thesis</div><img src='images/Bachelor-Degree-Thesis.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Research on Speech Separation Based on Audio Visual Model]()

**Kai Li**, Xiaolin Hu<sup>#</sup>, Jianqiang Huang<sup>#</sup>.

[**Audio Project Page**](./project/Pure-Audio/index.html) \| [**Audio-visual Project Page**](./project/AV-Demo/AV-Model-Demo.html)

</div>
</div>

## ðŸ“· Image Super Resolution
<div class='paper-box'><div class='paper-box-image'><div><div class="badge" style="background-color: green">Submitted IEEE Transactions on Industrial Informatics</div><img src='images/submitted.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Single Image Super-Resolution through Image Pixel Information Clustering and Generative Adversarial Network]()

**Kai Li**, Jianqiang Huang<sup>#</sup>, Jinfang Jia, Yu Zhu, Li Wu, Xiaoying Wang.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IET Image Processing 2020</div><img src='images/resolution_servey.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Survey of Single Image Super Resolution Reconstruction](./files/A_Survey_of_Single_Image_Super_Resolution_Reconstr.pdf)

**Kai Li**, Shenghao Yang, Runting Dong, Jianqiang Huang<sup>#</sup>, Xiaoying Wang.

**Citations: 25**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISPA 2019</div><img src='images/lapras-GAN.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Single Image Super-resolution Reconstruction of Enhanced Loss Function with Multi-GPU Training](./files/Single_Image_Super-Resolution_Reconstruction_of_Enhanced_Loss_Function_with_Multi-GPU_Training.pdf)

Jianqiang Huang<sup>*, #</sup>, **Kai Li$^*$**, Xiaoying Wang.

**Citations: 1**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICDIP 2019</div><img src='images/esrgan-pro.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Single image super resolution based on generative adversarial networks](./files/111790T.pdf)

**Kai Li**, Liang Ye, Shenghao Yang, Jianqiang Huang<sup>#</sup>, Xiaoying Wang.

</div>
</div>